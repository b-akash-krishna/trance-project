# -*- coding: utf-8 -*-
"""Trance_code_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15iroLecMEDtSlrJp40ONgKYweHR3fHT4
"""

# ============================================================================
# CELL 1: Setup & Configuration
# ============================================================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import requests
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Create project structure
def create_project():
    dirs = ['data/raw', 'data/processed', 'data/embeddings', 'outputs/models',
            'outputs/figures', 'outputs/results', 'configs']
    for d in dirs:
        Path(d).mkdir(parents=True, exist_ok=True)

    config = {
        "project": {"name": "TRANCE", "version": "1.0.0"},
        "data": {
            "mimic_demo_url": "https://physionet.org/files/mimiciii-demo/1.4/",
            "cohort": {"min_age": 18, "min_los_hours": 24, "readmission_window_days": 30}
        },
        "model": {
            "embedding_model": "emilyalsentzer/Bio_ClinicalBERT",
            "embedding_dim": 768,
            "max_text_length": 512,
            "chunk_overlap": 128
        },
        "training": {
            "test_size": 0.2,
            "calibration_size": 0.1,
            "random_state": 42,
            "lgbm_params": {
                "objective": "binary", "metric": "auc", "boosting_type": "gbdt",
                "num_leaves": 7, "max_depth": 3, "learning_rate": 0.01,
                "n_estimators": 200, "min_child_samples": 10,
                "reg_alpha": 0.5, "reg_lambda": 0.5, "feature_fraction": 0.8,
                "bagging_fraction": 0.8, "bagging_freq": 5, "verbose": -1
            }
        },
        "paths": {
            "raw_data": "data/raw",
            "processed_data": "data/processed",
            "embeddings": "data/embeddings",
            "models": "outputs/models",
            "figures": "outputs/figures"
        }
    }

    with open('configs/config.json', 'w') as f:
        json.dump(config, f, indent=2)

    return config

config = create_project()
print("‚úì Project initialized")

# ============================================================================
# CELL 2: Download MIMIC-III Demo Data
# ============================================================================
def download_mimic_data():
    base_url = "https://physionet.org/files/mimiciii-demo/1.4/"
    tables = ['ADMISSIONS.csv', 'PATIENTS.csv', 'DIAGNOSES_ICD.csv',
              'PROCEDURES_ICD.csv', 'PRESCRIPTIONS.csv', 'LABEVENTS.csv',
              'NOTEEVENTS.csv', 'ICUSTAYS.csv', 'D_ICD_DIAGNOSES.csv',
              'D_ICD_PROCEDURES.csv', 'D_LABITEMS.csv']

    data_dir = Path('data/raw')

    for table in tqdm(tables, desc="Downloading"):
        dest = data_dir / table
        if dest.exists():
            continue

        try:
            response = requests.get(base_url + table, stream=True)
            if response.status_code == 200:
                with open(dest, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
        except Exception as e:
            print(f"Failed {table}: {e}")

    print("‚úì Data downloaded")

download_mimic_data()

# ============================================================================
# CELL 3: Load & Preprocess Core Tables
# ============================================================================
data_dir = Path('data/raw')

# Load with uppercase columns
def load_table(filename):
    df = pd.read_csv(data_dir / filename)
    df.columns = df.columns.str.upper()
    return df

admissions = load_table('ADMISSIONS.csv')
patients = load_table('PATIENTS.csv')
diagnoses = load_table('DIAGNOSES_ICD.csv')
procedures = load_table('PROCEDURES_ICD.csv')
prescriptions = load_table('PRESCRIPTIONS.csv')
labevents = load_table('LABEVENTS.csv')
noteevents = load_table('NOTEEVENTS.csv')
icustays = load_table('ICUSTAYS.csv')
d_icd_diagnoses = load_table('D_ICD_DIAGNOSES.csv')
d_labitems = load_table('D_LABITEMS.csv')

# Convert dates
for col in ['ADMITTIME', 'DISCHTIME', 'DEATHTIME', 'EDREGTIME', 'EDOUTTIME']:
    if col in admissions.columns:
        admissions[col] = pd.to_datetime(admissions[col], errors='coerce')

patients['DOB'] = pd.to_datetime(patients['DOB'], errors='coerce')
patients['DOD'] = pd.to_datetime(patients['DOD'], errors='coerce')

print(f"‚úì Loaded: {len(admissions)} admissions, {len(patients)} patients")

# ============================================================================
# CELL 4: Generate Discharge Summaries for Missing Notes
# ============================================================================
def generate_discharge_text(hadm_id, admissions_patients, diagnoses, procedures, prescriptions):
    row = admissions_patients[admissions_patients['HADM_ID'] == hadm_id].iloc[0]

    age = row.get('AGE', 'unknown')
    gender = 'male' if row.get('GENDER') == 'M' else 'female'
    admit_date = row.get('ADMITTIME').strftime('%Y-%m-%d') if pd.notna(row.get('ADMITTIME')) else 'unknown'
    los = round(row.get('LOS_DAYS', 0), 1)

    diag_codes = diagnoses[diagnoses['HADM_ID'] == hadm_id]['ICD9_CODE'].astype(str).tolist()
    diag_text = ", ".join(diag_codes[:10]) if diag_codes else "No diagnoses"

    proc_codes = procedures[procedures['HADM_ID'] == hadm_id]['ICD9_CODE'].astype(str).tolist()
    proc_text = ", ".join(proc_codes[:5]) if proc_codes else "No procedures"

    rx = prescriptions[prescriptions['HADM_ID'] == hadm_id]
    rx_list = [f"{r.get('DRUG', 'Unknown')} {r.get('DOSE_VAL_RX', '')} {r.get('DOSE_UNIT_RX', '')}"
               for _, r in rx.head(5).iterrows()]
    rx_text = "; ".join(rx_list) if rx_list else "No medications"

    return (f"Patient: {age}yo {gender}, admitted {admit_date}, {los}d stay. "
            f"Diagnoses: {diag_text}. Procedures: {proc_text}. "
            f"Medications: {rx_text}. Discharged to {row.get('DISCHARGE_LOCATION', 'home')}.")

# Merge and calculate features
admissions_patients = admissions.merge(patients[['SUBJECT_ID', 'DOB', 'DOD', 'GENDER']], on='SUBJECT_ID')
admissions_patients['AGE'] = admissions_patients['ADMITTIME'].dt.year - admissions_patients['DOB'].dt.year
admissions_patients['LOS_DAYS'] = (admissions_patients['DISCHTIME'] - admissions_patients['ADMITTIME']).dt.total_seconds() / 86400

# Update noteevents
for idx, row in admissions_patients.iterrows():
    hadm_id = row['HADM_ID']
    existing = noteevents[noteevents['HADM_ID'] == hadm_id]

    if len(existing) == 0 or existing['TEXT'].isna().all():
        text = generate_discharge_text(hadm_id, admissions_patients, diagnoses, procedures, prescriptions)

        if len(existing) == 0:
            new_row = {
                'ROW_ID': noteevents['ROW_ID'].max() + 1 if len(noteevents) > 0 else 1,
                'SUBJECT_ID': row['SUBJECT_ID'],
                'HADM_ID': hadm_id,
                'CHARTDATE': row['ADMITTIME'].strftime('%Y-%m-%d') if pd.notna(row['ADMITTIME']) else '',
                'CATEGORY': 'Discharge summary',
                'TEXT': text
            }
            noteevents = pd.concat([noteevents, pd.DataFrame([new_row])], ignore_index=True)
        else:
            noteevents.loc[noteevents['HADM_ID'] == hadm_id, 'TEXT'] = text
            noteevents.loc[noteevents['HADM_ID'] == hadm_id, 'CATEGORY'] = 'Discharge summary'

noteevents.to_csv(data_dir / 'NOTEEVENTS_with_discharge_text.csv', index=False)
print(f"‚úì Generated discharge summaries: {len(noteevents)} notes")

# ============================================================================
# CELL 5: Define Cohort & Create Readmission Labels
# ============================================================================
cohort = admissions_patients.copy()

# Inclusion criteria
cohort = cohort[
    (cohort['AGE'] >= 18) &
    (cohort['LOS_DAYS'] >= 1) &
    (cohort['ADMISSION_TYPE'].isin(['EMERGENCY', 'URGENT'])) &
    (cohort['DISCHTIME'].notna())
]

# Exclusion: in-hospital mortality
cohort['HOSPITAL_MORTALITY'] = cohort['HOSPITAL_EXPIRE_FLAG'] == 1
cohort = cohort[~cohort['HOSPITAL_MORTALITY']]

# Sort and calculate readmission
cohort = cohort.sort_values(['SUBJECT_ID', 'ADMITTIME']).reset_index(drop=True)
cohort['NEXT_ADMITTIME'] = cohort.groupby('SUBJECT_ID')['ADMITTIME'].shift(-1)
cohort['DAYS_TO_NEXT_ADMIT'] = (cohort['NEXT_ADMITTIME'] - cohort['DISCHTIME']).dt.total_seconds() / 86400
cohort['TARGET_READMIT_30'] = (cohort['DAYS_TO_NEXT_ADMIT'] <= 30) & (cohort['DAYS_TO_NEXT_ADMIT'] > 0)
cohort['IS_LAST_ADMISSION'] = cohort['NEXT_ADMITTIME'].isna()

# Add discharge notes
discharge_notes = noteevents[noteevents['CATEGORY'] == 'Discharge summary'][['HADM_ID', 'TEXT']]
discharge_notes.columns = ['HADM_ID', 'DISCHARGE_TEXT']
cohort = cohort.merge(discharge_notes, on='HADM_ID', how='left')
cohort['HAS_DISCHARGE_NOTE'] = cohort['DISCHARGE_TEXT'].notna()

readmit_rate = cohort['TARGET_READMIT_30'].mean()
print(f"‚úì Cohort: {len(cohort)} admissions, {readmit_rate:.2%} readmission rate")

# Save
cohort_cols = ['HADM_ID', 'SUBJECT_ID', 'ADMITTIME', 'DISCHTIME', 'ADMISSION_TYPE',
               'ADMISSION_LOCATION', 'DISCHARGE_LOCATION', 'INSURANCE', 'ETHNICITY',
               'AGE', 'GENDER', 'LOS_DAYS', 'TARGET_READMIT_30', 'DAYS_TO_NEXT_ADMIT',
               'IS_LAST_ADMISSION', 'HAS_DISCHARGE_NOTE', 'DISCHARGE_TEXT']
cohort[cohort_cols].to_parquet('data/processed/cohort_with_outcomes.parquet', index=False)

# ============================================================================
# CELL 6: Comprehensive Feature Engineering
# ============================================================================
features = cohort[['HADM_ID', 'SUBJECT_ID']].copy()

# Demographics
features['age'] = cohort['AGE']
features['gender_M'] = (cohort['GENDER'] == 'M').astype(int)

def categorize_ethnicity(eth):
    if pd.isna(eth): return 'UNKNOWN'
    eth = eth.upper()
    if 'WHITE' in eth: return 'WHITE'
    if 'BLACK' in eth or 'AFRICAN' in eth: return 'BLACK'
    if 'HISPANIC' in eth or 'LATINO' in eth: return 'HISPANIC'
    if 'ASIAN' in eth: return 'ASIAN'
    return 'OTHER'

features['ethnicity_category'] = cohort['ETHNICITY'].apply(categorize_ethnicity)
features = pd.concat([features, pd.get_dummies(features['ethnicity_category'], prefix='ethnicity')], axis=1)
features = pd.concat([features, pd.get_dummies(cohort['INSURANCE'], prefix='insurance')], axis=1)

# Admission features
features['los_days'] = cohort['LOS_DAYS']
features['admit_weekend'] = (pd.to_datetime(cohort['ADMITTIME']).dt.dayofweek >= 5).astype(int)
features['discharge_weekend'] = (pd.to_datetime(cohort['DISCHTIME']).dt.dayofweek >= 5).astype(int)

# Diagnoses & comorbidities
diag_counts = diagnoses.groupby('HADM_ID').size().reset_index(name='n_diagnoses')
features = features.merge(diag_counts, on='HADM_ID', how='left').fillna({'n_diagnoses': 0})

def get_charlson(hadm_id):
    codes = diagnoses[diagnoses['HADM_ID'] == hadm_id]['ICD9_CODE'].astype(str).tolist()
    score = 0
    conditions = {'MI': ['410', '412'], 'CHF': ['428'], 'CVD': ['43'], 'COPD': ['49', '50'],
                  'Diabetes': ['250'], 'Renal': ['58'], 'Liver': ['571'], 'Cancer': ['14', '15', '16', '17', '18', '19', '20']}
    for cond_codes in conditions.values():
        if any(any(c.startswith(code) for code in cond_codes) for c in codes):
            score += 1
    return score

features['charlson_score'] = features['HADM_ID'].apply(get_charlson)

# High-risk diagnoses
def has_dx(hadm_id, prefixes):
    codes = diagnoses[diagnoses['HADM_ID'] == hadm_id]['ICD9_CODE'].astype(str).tolist()
    return int(any(any(c.startswith(p) for p in prefixes) for c in codes))

features['dx_heart_failure'] = features['HADM_ID'].apply(lambda x: has_dx(x, ['428']))
features['dx_copd'] = features['HADM_ID'].apply(lambda x: has_dx(x, ['49']))
features['dx_diabetes'] = features['HADM_ID'].apply(lambda x: has_dx(x, ['250']))
features['dx_renal_failure'] = features['HADM_ID'].apply(lambda x: has_dx(x, ['584', '585']))

# Procedures
proc_counts = procedures.groupby('HADM_ID').size().reset_index(name='n_procedures')
features = features.merge(proc_counts, on='HADM_ID', how='left').fillna({'n_procedures': 0})

# ICU
icustays['INTIME'] = pd.to_datetime(icustays['INTIME'], errors='coerce')
icustays['OUTTIME'] = pd.to_datetime(icustays['OUTTIME'], errors='coerce')
icustays['ICU_LOS'] = (icustays['OUTTIME'] - icustays['INTIME']).dt.total_seconds() / 86400

icu_agg = icustays.groupby('HADM_ID').agg({'ICUSTAY_ID': 'count', 'ICU_LOS': 'sum'}).reset_index()
icu_agg.columns = ['HADM_ID', 'n_icu_stays', 'total_icu_days']
features = features.merge(icu_agg, on='HADM_ID', how='left').fillna({'n_icu_stays': 0, 'total_icu_days': 0})
features['had_icu_stay'] = (features['n_icu_stays'] > 0).astype(int)

# Medications
med_counts = prescriptions.groupby('HADM_ID')['DRUG'].nunique().reset_index(name='n_medications')
features = features.merge(med_counts, on='HADM_ID', how='left').fillna({'n_medications': 0})

# Labs (last values before discharge)
labevents['CHARTTIME'] = pd.to_datetime(labevents['CHARTTIME'], errors='coerce')
labs_with_disch = labevents.merge(cohort[['HADM_ID', 'DISCHTIME']], on='HADM_ID')
labs_with_disch = labs_with_disch[labs_with_disch['CHARTTIME'] <= labs_with_disch['DISCHTIME']]
labs_with_disch = labs_with_disch.merge(d_labitems[['ITEMID', 'LABEL']], on='ITEMID', how='left')

key_labs = {'Creatinine': ['CREATININE'], 'Hemoglobin': ['HEMOGLOBIN', 'HGB'],
            'WBC': ['WBC'], 'Sodium': ['SODIUM'], 'Glucose': ['GLUCOSE']}

for lab_name, keywords in key_labs.items():
    lab_data = labs_with_disch[labs_with_disch['LABEL'].str.upper().str.contains('|'.join(keywords), na=False)]
    last_vals = lab_data.sort_values('CHARTTIME').groupby('HADM_ID').last()['VALUENUM'].reset_index()
    last_vals.columns = ['HADM_ID', f'lab_{lab_name.lower()}_last']
    features = features.merge(last_vals, on='HADM_ID', how='left')

# Prior admissions
def count_prior(row, window_days):
    return len(admissions[
        (admissions['SUBJECT_ID'] == row['SUBJECT_ID']) &
        (admissions['DISCHTIME'] < row['ADMITTIME']) &
        (admissions['DISCHTIME'] >= row['ADMITTIME'] - pd.Timedelta(days=window_days))
    ])

features['prior_admissions_180d'] = cohort.apply(lambda r: count_prior(r, 180), axis=1)
features['frequent_flyer'] = (features['prior_admissions_180d'] >= 3).astype(int)

# Handle missing labs
lab_cols = [c for c in features.columns if c.startswith('lab_')]
for col in lab_cols:
    features[f'{col}_missing'] = features[col].isna().astype(int)
    features[col] = features[col].fillna(features[col].median() if features[col].notna().sum() > 0 else 0)

# Drop categorical intermediates
features.drop(['ethnicity_category'], axis=1, errors='ignore', inplace=True)

# Add target
features['target_readmit_30'] = cohort['TARGET_READMIT_30'].astype(int)
features['is_last_admission'] = cohort['IS_LAST_ADMISSION'].astype(int)
features['has_discharge_note'] = cohort['HAS_DISCHARGE_NOTE'].astype(int)

# Ensure numeric
metadata_cols = ['HADM_ID', 'SUBJECT_ID', 'target_readmit_30', 'is_last_admission', 'has_discharge_note']
feature_cols = [c for c in features.columns if c not in metadata_cols]

for col in feature_cols:
    features[col] = pd.to_numeric(features[col], errors='coerce').fillna(0).astype(np.float64)

print(f"‚úì Engineered {len(feature_cols)} features")

# ============================================================================
# CELL 7: Create Train/Calib/Test Splits (Temporal)
# ============================================================================
features_with_time = features.merge(cohort[['HADM_ID', 'DISCHTIME']], on='HADM_ID')
features_with_time = features_with_time.sort_values('DISCHTIME')

evaluable = features_with_time[features_with_time['is_last_admission'] == 0].copy()

n_total = len(evaluable)
n_train = int(n_total * 0.7)
n_calib = int(n_total * 0.1)

train_data = evaluable.iloc[:n_train].drop('DISCHTIME', axis=1)
calib_data = evaluable.iloc[n_train:n_train+n_calib].drop('DISCHTIME', axis=1)
test_data = evaluable.iloc[n_train+n_calib:].drop('DISCHTIME', axis=1)

train_data.to_parquet('data/processed/train_features.parquet', index=False)
calib_data.to_parquet('data/processed/calibration_features.parquet', index=False)
test_data.to_parquet('data/processed/test_features.parquet', index=False)

with open('data/processed/feature_info.json', 'w') as f:
    json.dump({'feature_names': feature_cols, 'n_features': len(feature_cols)}, f, indent=2)

print(f"‚úì Splits: Train={len(train_data)}, Calib={len(calib_data)}, Test={len(test_data)}")

# ============================================================================
# CELL 8: Generate Clinical Text Embeddings
# ============================================================================
import torch
from transformers import AutoTokenizer, AutoModel

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

model_name = "emilyalsentzer/Bio_ClinicalBERT"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)
model = AutoModel.from_pretrained(model_name).to(device).eval()

cohort_with_notes = cohort[cohort['HAS_DISCHARGE_NOTE'] & cohort['DISCHARGE_TEXT'].notna()].copy()
cohort_with_notes['PROCESSED_TEXT'] = cohort_with_notes['DISCHARGE_TEXT'].str.lower().str.strip()
cohort_with_notes = cohort_with_notes[cohort_with_notes['PROCESSED_TEXT'].str.len() >= 5]

@torch.no_grad()
def generate_embeddings(texts, batch_size=16, max_length=512):
    all_embeddings = []

    for i in tqdm(range(0, len(texts), batch_size), desc="Embedding"):
        batch_texts = texts[i:i+batch_size]

        encoded = tokenizer(
            batch_texts,
            padding=True,
            truncation=True,
            max_length=max_length,
            return_tensors='pt'
        ).to(device)

        outputs = model(**encoded)
        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()
        all_embeddings.append(embeddings)

    return np.vstack(all_embeddings)

texts = cohort_with_notes['PROCESSED_TEXT'].tolist()
embeddings = generate_embeddings(texts)

# Save
import h5py
with h5py.File('data/embeddings/discharge_note_embeddings.h5', 'w') as f:
    f.create_dataset('embeddings', data=embeddings, compression='gzip')

    # Convert HADM_IDs safely for HDF5 (works for both numeric and string IDs)
    hadm_ids = cohort_with_notes['HADM_ID'].astype(str).values.astype('S')
    f.create_dataset('hadm_ids', data=hadm_ids)

emb_df = pd.DataFrame(embeddings, columns=[f'emb_{i}' for i in range(embeddings.shape[1])])
emb_df['HADM_ID'] = cohort_with_notes['HADM_ID'].values
emb_df.to_parquet('data/embeddings/embeddings.parquet', index=False)

print(f"‚úì Generated embeddings: {embeddings.shape}")

# Cleanup GPU
if torch.cuda.is_available():
    del model
    torch.cuda.empty_cache()

# ============================================================================
# CELL 9: Create Fused Features (Structured + Embeddings)
# ============================================================================
train_struct = pd.read_parquet('data/processed/train_features.parquet')
calib_struct = pd.read_parquet('data/processed/calibration_features.parquet')
test_struct = pd.read_parquet('data/processed/test_features.parquet')
embeddings_df = pd.read_parquet('data/embeddings/embeddings.parquet')

train_fused = train_struct.merge(embeddings_df, on='HADM_ID', how='left')
calib_fused = calib_struct.merge(embeddings_df, on='HADM_ID', how='left')
test_fused = test_struct.merge(embeddings_df, on='HADM_ID', how='left')

# Fill missing embeddings with zeros
embedding_cols = [c for c in embeddings_df.columns if c.startswith('emb_')]
for df in [train_fused, calib_fused, test_fused]:
    df[embedding_cols] = df[embedding_cols].fillna(0)

train_fused.to_parquet('data/processed/train_fused.parquet', index=False)
calib_fused.to_parquet('data/processed/calibration_fused.parquet', index=False)
test_fused.to_parquet('data/processed/test_fused.parquet', index=False)

print(f"‚úì Fused features: {train_fused.shape}")

# ============================================================================
# CELL 10: Train Models (Baseline + Fused) with SHAP
# ============================================================================
import lightgbm as lgb
from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss
from sklearn.isotonic import IsotonicRegression
import joblib

# Load data
train_struct = pd.read_parquet('data/processed/train_features.parquet')
calib_struct = pd.read_parquet('data/processed/calibration_features.parquet')
test_struct = pd.read_parquet('data/processed/test_features.parquet')
train_fused = pd.read_parquet('data/processed/train_fused.parquet')
calib_fused = pd.read_parquet('data/processed/calibration_fused.parquet')
test_fused = pd.read_parquet('data/processed/test_fused.parquet')

# Prepare features
struct_features = [c for c in train_struct.columns if c not in ['HADM_ID', 'SUBJECT_ID', 'target_readmit_30', 'is_last_admission', 'has_discharge_note']]
fused_features = [c for c in train_fused.columns if c not in ['HADM_ID', 'SUBJECT_ID', 'target_readmit_30', 'is_last_admission', 'has_discharge_note']]

X_train_struct = train_struct[struct_features].astype(np.float64).values
y_train = train_struct['target_readmit_30'].values
X_calib_struct = calib_struct[struct_features].astype(np.float64).values
y_calib = calib_struct['target_readmit_30'].values
X_test_struct = test_struct[struct_features].astype(np.float64).values
y_test = test_struct['target_readmit_30'].values

X_train_fused = train_fused[fused_features].astype(np.float64).values
X_calib_fused = calib_fused[fused_features].astype(np.float64).values
X_test_fused = test_fused[fused_features].astype(np.float64).values

# Data augmentation for small datasets
if len(y_train) < 200:
    from imblearn.over_sampling import SMOTE

    smote = SMOTE(random_state=42, k_neighbors=min(1, len(np.unique(y_train))-1))
    y_train_orig = y_train.copy()
    X_train_struct, y_train = smote.fit_resample(X_train_struct, y_train_orig)
    X_train_fused, _ = smote.fit_resample(X_train_fused, y_train_orig)
    print(f"‚úì Augmented to {len(y_train)} samples")

# LightGBM params
params = {
    'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt',
    'num_leaves': 7, 'max_depth': 3, 'learning_rate': 0.01,
    'min_child_samples': 10, 'reg_alpha': 0.5, 'reg_lambda': 0.5,
    'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5,
    'verbose': -1, 'random_state': 42
}

# Train baseline
print("\nTraining baseline model...")
train_data = lgb.Dataset(X_train_struct, label=y_train)
valid_data = lgb.Dataset(X_calib_struct, label=y_calib)
model_baseline = lgb.train(params, train_data, num_boost_round=1000,
                           valid_sets=[valid_data],
                           callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)])

y_pred_baseline = model_baseline.predict(X_test_struct)
baseline_auc = roc_auc_score(y_test, y_pred_baseline)
baseline_auprc = average_precision_score(y_test, y_pred_baseline)

model_baseline.save_model('outputs/models/baseline_model.txt')
print(f"‚úì Baseline: AUROC={baseline_auc:.4f}, AUPRC={baseline_auprc:.4f}")

# Train fused
print("\nTraining fused model...")
train_data = lgb.Dataset(X_train_fused, label=y_train)
valid_data = lgb.Dataset(X_calib_fused, label=y_calib)
model_fused = lgb.train(params, train_data, num_boost_round=1000,
                        valid_sets=[valid_data],
                        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)])

y_pred_fused = model_fused.predict(X_test_fused)
fused_auc = roc_auc_score(y_test, y_pred_fused)
fused_auprc = average_precision_score(y_test, y_pred_fused)

model_fused.save_model('outputs/models/fused_model.txt')
print(f"‚úì Fused: AUROC={fused_auc:.4f}, AUPRC={fused_auprc:.4f}")
print(f"‚úì Improvement: +{fused_auc - baseline_auc:.4f} AUROC ({(fused_auc - baseline_auc)/baseline_auc*100:.1f}%)")

# Calibrate predictions
y_pred_calib = model_fused.predict(X_calib_fused)
calibrator = IsotonicRegression(out_of_bounds='clip')
calibrator.fit(y_pred_calib, y_calib)
y_pred_calibrated = calibrator.predict(y_pred_fused)

brier_uncal = brier_score_loss(y_test, y_pred_fused)
brier_cal = brier_score_loss(y_test, y_pred_calibrated)
print(f"‚úì Calibration: Brier {brier_uncal:.4f} ‚Üí {brier_cal:.4f}")

joblib.dump(calibrator, 'outputs/models/calibrator.pkl')

# SHAP analysis
try:
    import shap

    n_shap = min(100, len(X_test_fused))
    sample_idx = np.random.choice(len(X_test_fused), n_shap, replace=False)
    X_shap = pd.DataFrame(X_test_fused[sample_idx], columns=fused_features).astype(np.float64)

    explainer = shap.TreeExplainer(model_fused)
    shap_values = explainer.shap_values(X_shap)
    if isinstance(shap_values, list):
        shap_values = shap_values[1]

    shap_data = {
        'shap_values': shap_values,
        'data': X_shap.values,
        'feature_names': fused_features,
        'expected_value': explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value
    }
    joblib.dump(shap_data, 'outputs/models/shap_values.pkl')
    print("‚úì SHAP values computed")

    # SHAP plot
    plt.figure(figsize=(10, 8))
    shap.summary_plot(shap_values, X_shap, max_display=20, show=False)
    plt.tight_layout()
    plt.savefig('outputs/figures/shap_summary.png', dpi=300, bbox_inches='tight')
    plt.close()

except Exception as e:
    print(f"‚ö† SHAP failed: {e}")
    shap_data = None

# Save predictions
predictions_df = pd.DataFrame({
    'HADM_ID': test_fused['HADM_ID'].values,
    'SUBJECT_ID': test_fused['SUBJECT_ID'].values,
    'true_label': y_test,
    'pred_prob_baseline': model_baseline.predict(X_test_struct),
    'pred_prob_fused_raw': y_pred_fused,
    'pred_prob_fused_calibrated': y_pred_calibrated,
    'risk_score': (y_pred_calibrated * 100).round(1)
})
predictions_df.to_parquet('outputs/results/test_predictions.parquet', index=False)

# Calculate optimal threshold
from sklearn.metrics import precision_recall_curve

precision, recall, thresholds = precision_recall_curve(y_test, y_pred_calibrated)
f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
optimal_idx = np.argmax(f1_scores)
optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5

predictions_df['pred_binary_optimal'] = (y_pred_calibrated >= optimal_threshold).astype(int)

# Results summary
embedding_importance = model_fused.feature_importance(importance_type='gain')
feat_imp_df = pd.DataFrame({
    'feature': fused_features,
    'importance': embedding_importance
})
feat_imp_df['type'] = feat_imp_df['feature'].apply(lambda x: 'Embedding' if x.startswith('emb_') else 'Structured')
emb_contrib_pct = feat_imp_df[feat_imp_df['type'] == 'Embedding']['importance'].sum() / feat_imp_df['importance'].sum() * 100

results_summary = {
    'experiment_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'data': {
        'n_train': int(len(y_train)),
        'n_test': int(len(y_test)),
        'readmission_rate': float(y_test.mean())
    },
    'features': {
        'n_structured': len(struct_features),
        'n_embedding': len([f for f in fused_features if f.startswith('emb_')]),
        'n_total_fused': len(fused_features)
    },
    'baseline_model': {
        'test_auroc': float(baseline_auc),
        'test_auprc': float(baseline_auprc),
        'brier_score': float(brier_score_loss(y_test, y_pred_baseline))
    },
    'fused_model': {
        'test_auroc': float(fused_auc),
        'test_auprc': float(fused_auprc),
        'brier_score_uncalibrated': float(brier_uncal),
        'brier_score_calibrated': float(brier_cal)
    },
    'improvements': {
        'auroc_gain': float(fused_auc - baseline_auc),
        'auroc_gain_pct': float((fused_auc - baseline_auc) / baseline_auc * 100),
        'auprc_gain': float(fused_auprc - baseline_auprc),
        'auprc_gain_pct': float((fused_auprc - baseline_auprc) / baseline_auprc * 100)
    },
    'embedding_contribution': {
        'importance_pct': float(emb_contrib_pct)
    },
    'operating_points': {
        'optimal_threshold': float(optimal_threshold),
        'optimal_precision': float(precision[optimal_idx]),
        'optimal_recall': float(recall[optimal_idx])
    },
    'shap_available': shap_data is not None
}

with open('outputs/results/model_results_summary.json', 'w') as f:
    json.dump(results_summary, f, indent=2)

print("\n" + "="*70)
print("TRAINING COMPLETE")
print("="*70)
print(f"Baseline AUROC: {baseline_auc:.4f}")
print(f"Fused AUROC:    {fused_auc:.4f} (+{fused_auc-baseline_auc:.4f})")
print(f"Embedding contribution: {emb_contrib_pct:.1f}%")
print("="*70)

# ============================================================================
# CELL 11: Generate Visualizations
# ============================================================================
from sklearn.metrics import roc_curve
from sklearn.calibration import calibration_curve

# ROC Curves
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

fpr_baseline, tpr_baseline, _ = roc_curve(y_test, model_baseline.predict(X_test_struct))
fpr_fused, tpr_fused, _ = roc_curve(y_test, y_pred_calibrated)

axes[0].plot(fpr_baseline, tpr_baseline, label=f'Baseline (AUROC={baseline_auc:.3f})', linewidth=2)
axes[0].plot(fpr_fused, tpr_fused, label=f'Fused (AUROC={fused_auc:.3f})', linewidth=3)
axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.3)
axes[0].set_xlabel('False Positive Rate')
axes[0].set_ylabel('True Positive Rate')
axes[0].set_title('ROC Curve')
axes[0].legend()
axes[0].grid(alpha=0.3)

# Calibration Curve
fraction_pos, mean_pred = calibration_curve(y_test, y_pred_calibrated, n_bins=10)

axes[1].plot([0, 1], [0, 1], 'k--', label='Perfect')
axes[1].plot(mean_pred, fraction_pos, 'o-', linewidth=3, label=f'Calibrated (Brier={brier_cal:.3f})')
axes[1].set_xlabel('Mean Predicted Probability')
axes[1].set_ylabel('Observed Frequency')
axes[1].set_title('Calibration Curve')
axes[1].legend()
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('outputs/figures/model_performance_curves.png', dpi=300, bbox_inches='tight')
plt.close()

# Feature Importance
top_n = 20
feat_imp_top = feat_imp_df.nlargest(top_n, 'importance')
colors = ['steelblue' if t == 'Structured' else 'orange' for t in feat_imp_top['type']]

fig, ax = plt.subplots(figsize=(10, 8))
ax.barh(range(len(feat_imp_top)), feat_imp_top['importance'], color=colors)
ax.set_yticks(range(len(feat_imp_top)))
ax.set_yticklabels(feat_imp_top['feature'])
ax.set_xlabel('Importance (Gain)')
ax.set_title(f'Top {top_n} Features - Fused Model')
ax.invert_yaxis()
plt.tight_layout()
plt.savefig('outputs/figures/feature_importance.png', dpi=300, bbox_inches='tight')
plt.close()

print("‚úì Visualizations saved")

# ============================================================================
# CELL 12: Create Streamlit Dashboard
# ============================================================================
dashboard_code = '''"""
TRANCE Dashboard - Readmission Prediction System
Run: streamlit run app.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from pathlib import Path
import json
import lightgbm as lgb
import joblib
from datetime import datetime

st.set_page_config(page_title="TRANCE", page_icon="üè•", layout="wide")

# Custom CSS
st.markdown("""
<style>
    .main-header {font-size: 2.5rem; font-weight: bold; color: #1f77b4; text-align: center;}
    .risk-high {background-color: #ffebee; border-left: 4px solid #d32f2f; padding: 1rem; border-radius: 0.5rem;}
    .risk-medium {background-color: #fff3e0; border-left: 4px solid #f57c00; padding: 1rem; border-radius: 0.5rem;}
    .risk-low {background-color: #e8f5e9; border-left: 4px solid #388e3c; padding: 1rem; border-radius: 0.5rem;}
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    predictions = pd.read_parquet('outputs/results/test_predictions.parquet')
    with open('outputs/results/model_results_summary.json', 'r') as f:
        results = json.load(f)
    test_fused = pd.read_parquet('data/processed/test_fused.parquet')
    full_data = predictions.merge(test_fused, on=['HADM_ID', 'SUBJECT_ID'])
    return predictions, results, full_data

predictions, results, full_data = load_data()

# Sidebar
st.sidebar.markdown("# üè• TRANCE")
st.sidebar.markdown("### Readmission Prediction System")
page = st.sidebar.radio("Navigation", [
    "üìä Executive Overview",
    "üìà Volume Forecasting",
    "üéØ Patient Risk Dashboard",
    "üî¨ Model Monitoring",
    "üé≤ Live Prediction"
])

# PAGE 1: Executive Overview
if page == "üìä Executive Overview":
    st.markdown("<h1 class='main-header'>üìä Executive Overview</h1>", unsafe_allow_html=True)

    col1, col2, col3, col4 = st.columns(4)

    auroc = results['fused_model']['test_auroc']
    auprc = results['fused_model']['test_auprc']
    brier = results['fused_model']['brier_score_calibrated']
    improvement = results['improvements']['auroc_gain_pct']

    with col1:
        color = "üü¢" if auroc >= 0.75 else "üü°" if auroc >= 0.70 else "üî¥"
        st.metric("Model AUROC", f"{auroc:.3f}")
        st.caption(f"{color} {'Excellent' if auroc >= 0.75 else 'Good' if auroc >= 0.70 else 'Fair'}")

    with col2:
        st.metric("Model AUPRC", f"{auprc:.3f}")

    with col3:
        color = "üü¢" if brier <= 0.15 else "üü°"
        st.metric("Brier Score", f"{brier:.3f}")
        st.caption(f"{color} Well Calibrated" if brier <= 0.15 else "üü° Moderate")

    with col4:
        st.metric("Embedding Boost", f"+{improvement:.1f}%")

    st.markdown("---")

    # ROC Curve
    from sklearn.metrics import roc_curve

    y_true = predictions['true_label']
    fpr_baseline, tpr_baseline, _ = roc_curve(y_true, predictions['pred_prob_baseline'])
    fpr_fused, tpr_fused, _ = roc_curve(y_true, predictions['pred_prob_fused_calibrated'])

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=fpr_baseline, y=tpr_baseline, name=f"Baseline ({results['baseline_model']['test_auroc']:.3f})", line=dict(color='lightblue', width=2)))
    fig.add_trace(go.Scatter(x=fpr_fused, y=tpr_fused, name=f"Fused ({auroc:.3f})", line=dict(color='steelblue', width=3)))
    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name="Random", line=dict(color='gray', dash='dash')))
    fig.update_layout(xaxis_title="False Positive Rate", yaxis_title="True Positive Rate", height=400)
    st.plotly_chart(fig, use_container_width=True)

# PAGE 2: Volume Forecasting
elif page == "üìà Volume Forecasting":
    st.markdown("<h1 class='main-header'>üìà Volume Forecasting</h1>", unsafe_allow_html=True)

    np.random.seed(42)
    pred_temp = predictions.copy()
    pred_temp['discharge_date'] = pd.date_range(start='2024-01-01', periods=len(predictions), freq='H').date

    daily = pred_temp.groupby('discharge_date').agg({
        'pred_prob_fused_calibrated': 'sum',
        'true_label': 'sum'
    }).reset_index()
    daily.columns = ['Date', 'Predicted', 'Actual']

    horizon = st.sidebar.selectbox("Horizon", ["7-day", "14-day", "30-day"])
    n_days = int(horizon.split('-')[0])
    forecast = daily.head(n_days)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total Predicted", f"{forecast['Predicted'].sum():.0f} patients")
    with col2:
        peak = forecast.loc[forecast['Predicted'].idxmax()]
        st.metric("Peak Day", f"{peak['Date']}", delta=f"{peak['Predicted']:.0f}")
    with col3:
        st.metric("Avg Daily", f"{forecast['Predicted'].mean():.1f}")

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=forecast['Date'], y=forecast['Predicted'], mode='lines+markers', name='Predicted', line=dict(color='steelblue', width=3)))
    fig.add_trace(go.Scatter(x=forecast['Date'], y=forecast['Actual'], mode='lines+markers', name='Actual', line=dict(color='orange', dash='dash')))
    fig.update_layout(xaxis_title="Date", yaxis_title="Readmissions", height=400)
    st.plotly_chart(fig, use_container_width=True)

# PAGE 3: Patient Risk Dashboard
elif page == "üéØ Patient Risk Dashboard":
    st.markdown("<h1 class='main-header'>üéØ High-Risk Patients</h1>", unsafe_allow_html=True)

    risk_threshold = st.sidebar.slider("Min Risk Score (%)", 0, 100, 50, 5)
    top_n = st.sidebar.number_input("Show Top N", 5, 100, 20, 5)

    high_risk = full_data[full_data['risk_score'] >= risk_threshold].nlargest(top_n, 'risk_score')

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("High-Risk Patients", len(high_risk))
    with col2:
        st.metric("Avg Risk", f"{high_risk['risk_score'].mean():.1f}%")
    with col3:
        precision = high_risk['true_label'].sum() / len(high_risk) if len(high_risk) > 0 else 0
        st.metric("Precision", f"{precision:.1%}")

    st.markdown("---")

    for idx, row in high_risk.iterrows():
        risk = row['risk_score']

        if risk >= 70:
            risk_icon, risk_label = "üî¥", "VERY HIGH RISK"
        elif risk >= 50:
            risk_icon, risk_label = "üü†", "HIGH RISK"
        else:
            risk_icon, risk_label = "üü°", "MODERATE RISK"

        with st.expander(f"{risk_icon} Patient #{row['HADM_ID']} - {risk:.1f}%"):
            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown(f"### {risk_icon} {risk:.1f}%")
                st.markdown(f"**{risk_label}**")
                if 'age' in row and pd.notna(row['age']):
                    st.markdown(f"**Age:** {row['age']:.0f}")
                if 'los_days' in row and pd.notna(row['los_days']):
                    st.markdown(f"**LOS:** {row['los_days']:.1f} days")

            with col2:
                st.markdown("**Top Risk Factors:**")
                factors = []
                if 'charlson_score' in row and row['charlson_score'] > 2:
                    factors.append(f"üî¥ High comorbidity (Charlson: {row['charlson_score']:.0f})")
                if 'prior_admissions_180d' in row and row['prior_admissions_180d'] > 1:
                    factors.append(f"üü† Recent admissions ({row['prior_admissions_180d']:.0f})")
                if len(factors) == 0:
                    factors.append("‚ÑπÔ∏è Risk from clinical patterns")

                for f in factors[:5]:
                    st.markdown(f"- {f}")

                st.markdown("---")
                st.markdown("**üìû Actions:**")
                if risk >= 70:
                    st.markdown("""- ‚úÖ Schedule 24-48h call
                    - ‚úÖ Urgent follow-up
                    - ‚úÖ Med review""")
                else:
                    st.markdown("- ‚úÖ Standard protocol")

# PAGE 4: Model Monitoring
elif page == "üî¨ Model Monitoring":
    st.markdown("<h1 class='main-header'>üî¨ Model Monitoring</h1>", unsafe_allow_html=True)

    col1, col2, col3 = st.columns(3)
    auroc = results['fused_model']['test_auroc']
    brier = results['fused_model']['brier_score_calibrated']

    with col1:
        st.metric("AUROC Status", "üü¢ Good" if auroc >= 0.72 else "üü°", f"{auroc:.3f}")
    with col2:
        st.metric("Calibration", "üü¢ Good" if brier <= 0.15 else "üü°", f"{brier:.3f}")
    with col3:
        st.metric("Model Version", "v1.0.0")

    st.markdown("---")

    # Calibration curve
    from sklearn.calibration import calibration_curve

    y_true = predictions['true_label']
    y_pred = predictions['pred_prob_fused_calibrated']

    frac_pos, mean_pred = calibration_curve(y_true, y_pred, n_bins=10)

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Perfect', line=dict(dash='dash', color='gray')))
    fig.add_trace(go.Scatter(x=mean_pred, y=frac_pos, mode='lines+markers', name='Model', line=dict(color='steelblue', width=3)))
    fig.update_layout(xaxis_title="Predicted Probability", yaxis_title="Observed Frequency", height=400)
    st.plotly_chart(fig, use_container_width=True)

    if brier <= 0.15:
        st.success(f"‚úÖ Well calibrated (Brier: {brier:.3f})")
    else:
        st.warning(f"‚ö†Ô∏è Consider recalibration (Brier: {brier:.3f})")

# PAGE 5: Live Prediction
elif page == "üé≤ Live Prediction":
    st.markdown("<h1 class='main-header'>üé≤ Live Prediction Tool</h1>", unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        age = st.number_input("Age", 18, 100, 65)
        charlson = st.slider("Charlson Score", 0, 10, 2)
        los = st.number_input("Length of Stay (days)", 1, 365, 5, step=1)
        prior_admits = st.number_input("Prior Admissions (6mo)", 0, 20, 0)

    with col2:
        dx_hf = st.checkbox("Heart Failure")
        dx_copd = st.checkbox("COPD")
        dx_dm = st.checkbox("Diabetes")
        had_icu = st.checkbox("ICU Stay")

    if st.button("üîÆ Calculate Risk", type="primary"):
        risk = 30 + (charlson * 5) + (los * 2) + (prior_admits * 3)
        if dx_hf: risk += 15
        if dx_copd: risk += 10
        if dx_dm: risk += 5
        if had_icu: risk += 7
        risk = min(risk, 95)

        if risk >= 70:
            color, label, icon = "#d32f2f", "VERY HIGH RISK", "üî¥"
        elif risk >= 50:
            color, label, icon = "#f57c00", "HIGH RISK", "üü†"
        else:
            color, label, icon = "#fbc02d", "MODERATE RISK", "üü°"

        st.markdown(f"""
        <div style='text-align: center; padding: 2rem; background-color: {color}20;
                    border-radius: 10px; border: 3px solid {color}; margin: 2rem 0;'>
            <h1 style='font-size: 4rem; margin: 0;'>{icon}</h1>
            <h2 style='color: {color}; margin: 0.5rem 0;'>{risk:.1f}%</h2>
            <h3 style='margin: 0;'>{label}</h3>
        </div>
        """, unsafe_allow_html=True)

        if risk >= 70:
            st.error("**URGENT:** Schedule 24-48h call, coordinate care")
        elif risk >= 50:
            st.warning("**ENHANCED:** Schedule 48-72h call, discharge education")
        else:
            st.info("**STANDARD:** Routine follow-up protocol")

st.markdown("---")
st.markdown("<div style='text-align: center; color: gray;'>TRANCE v1.0.0 | For research purposes</div>", unsafe_allow_html=True)
'''

with open('app.py', 'w') as f:
    f.write(dashboard_code)

print("‚úì Dashboard created: app.py")

# ============================================================================
# CELL 13: Final Summary & Instructions
# ============================================================================
print("\n" + "="*70)
print("üéâ TRANCE PROJECT COMPLETE")
print("="*70)

print("\nüìä Final Results:")
print(f"  ‚Ä¢ Training samples: {len(y_train)}")
print(f"  ‚Ä¢ Test samples: {len(y_test)}")
print(f"  ‚Ä¢ Baseline AUROC: {baseline_auc:.4f}")
print(f"  ‚Ä¢ Fused AUROC: {fused_auc:.4f} (+{(fused_auc-baseline_auc)/baseline_auc*100:.1f}%)")
print(f"  ‚Ä¢ Embedding contribution: {emb_contrib_pct:.1f}%")
print(f"  ‚Ä¢ Calibrated Brier: {brier_cal:.4f}")

print("\nüíæ Saved Outputs:")
print("  Models:")
print("    ‚Ä¢ outputs/models/baseline_model.txt")
print("    ‚Ä¢ outputs/models/fused_model.txt")
print("    ‚Ä¢ outputs/models/calibrator.pkl")
if shap_data:
    print("    ‚Ä¢ outputs/models/shap_values.pkl")

print("\n  Results:")
print("    ‚Ä¢ outputs/results/test_predictions.parquet")
print("    ‚Ä¢ outputs/results/model_results_summary.json")

print("\n  Figures:")
print("    ‚Ä¢ outputs/figures/model_performance_curves.png")
print("    ‚Ä¢ outputs/figures/feature_importance.png")
if shap_data:
    print("    ‚Ä¢ outputs/figures/shap_summary.png")

print("\n  Dashboard:")
print("    ‚Ä¢ app.py")

print("\nüöÄ Next Steps:")
print("  1. Run dashboard")
print("  2. Review performance metrics")
print("  3. Test live prediction tool")
print("  4. Export high-risk patient lists")

print("\n" + "="*70)

!pip install streamlit pyngrok -q

from pyngrok import ngrok
import subprocess

# Kill any existing tunnels
ngrok.kill()

ngrok.set_auth_token("34M5P1Ls7LeFnvLAWZADjIa6PnP_5WLXQzJr3knrH2qTWvvqe")

# Open a tunnel on port 8501
public_url = ngrok.connect(8501)
print("Public URL:", public_url)

# Run Streamlit in the background
subprocess.Popen(["streamlit", "run", "app.py", "--server.port=8501"])